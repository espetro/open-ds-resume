### Lab 1

***It  should be noted that the `collect()`  function brings all of the data into  the driver node. For a small dataset, this is acceptable but, for a  large dataset this can cause an Out Of Memory error. It is recommended  to use collect() for testing only. The safer approach is to use the  take() function e.g. print take(n)***



- How Spark caching can be used to pull data sets into a cluster-wide  in-memory cache. This is very useful for accessing repeated data, such  as querying a small “hot” dataset or when running an iterative algorithm



### Lab 2

